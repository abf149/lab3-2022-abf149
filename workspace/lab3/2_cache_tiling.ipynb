{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Tiling and Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use the fiber-tree emulator to display the behavior of various matrix multiplications for dense data. Because the data is assumed to be dense we use the position-based operators on the premise that for dense data the position and coordinate are the same.\n",
    "\n",
    "In Einsum notation we will be computing the following same as the Part 1:\n",
    "\n",
    "$$\n",
    "C_{m,n} = \\sum_k A_{m,k} \\times B_{k,n}\n",
    "$$\n",
    "\n",
    "In particular, we will observe how __matrix tiling__ changes the memory access pattern. Fibertree will provide an intuitive visualization of matrix tiling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run boilerplate code to set up environment\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from cache import Cache, CacheAssoc\n",
    "\n",
    "%run ./prelude.py --style=uncompressed --animation=movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication Input Selections\n",
    "\n",
    "Tiling is expressed by splitting the shape of each rank into two factors, e.g., M1 and M0, where the product is the full shape of the dimension, e.g., M = M1 x M0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initial values\n",
    "M1 = 2\n",
    "M0 = 2\n",
    "K1 = 2\n",
    "K0 = 2\n",
    "N1 = 2\n",
    "N0 = 2\n",
    "\n",
    "density = [1.0]\n",
    "seed = 10\n",
    "\n",
    "enable_log = False\n",
    "\n",
    "def set_params(**kwargs):\n",
    "    global enable_log\n",
    "    \n",
    "    for variable, value in kwargs.items():\n",
    "        globals()[variable] = value\n",
    "\n",
    "    enable_log = (kwargs[\"log\"] == 'enable')\n",
    "\n",
    "\n",
    "def logger(arg):\n",
    "    if enable_log:\n",
    "        print(arg)\n",
    "\n",
    "controls = interactive(set_params,\n",
    "                       M1=widgets.IntSlider(min=1, max=4, step=1, value=M1),\n",
    "                       M0=widgets.IntSlider(min=1, max=4, step=1, value=M0),\n",
    "                       K1=widgets.IntSlider(min=1, max=4, step=1, value=K1),\n",
    "                       K0=widgets.IntSlider(min=1, max=4, step=1, value=K0),\n",
    "                       N1=widgets.IntSlider(min=1, max=4, step=1, value=N1),\n",
    "                       N0=widgets.IntSlider(min=1, max=4, step=1, value=N0),\n",
    "                       seed=widgets.IntSlider(min=0, max=100, step=1, value=seed),\n",
    "                       log=['disable', 'enable'])\n",
    "\n",
    "display(controls)\n",
    "createRunallButton()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Input Tensors\n",
    "\n",
    "Given shapes selected above create and display the filter weights (**f**) and input activations (**i**) and a reference output (**o_verify**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = M1*M0\n",
    "K = K1*K0\n",
    "N = N1*N0\n",
    "\n",
    "a_MK_raw = []\n",
    "for m in range(M):\n",
    "    a_MK_raw.append([random.randint(1, 9) for i in range(K)])\n",
    "                 \n",
    "b_KN_raw = []\n",
    "for k in range(K):\n",
    "    b_KN_raw.append([random.randint(1, 9) for i in range(N)])\n",
    "\n",
    "a_MK = Tensor.fromUncompressed([\"M\", \"K\"], a_MK_raw)\n",
    "b_KN = Tensor.fromUncompressed([\"K\", \"N\"], b_KN_raw)\n",
    "\n",
    "a_MK.setName(\"A_MK\").setColor(\"blue\")\n",
    "b_KN.setName(\"B_KN\").setColor(\"green\")\n",
    "\n",
    "print(\"Input A\")\n",
    "displayTensor(a_MK)\n",
    "                    \n",
    "print(\"Input B\")\n",
    "displayTensor(b_KN)\n",
    "\n",
    "z_verify = None\n",
    "\n",
    "def create_z():\n",
    "    \"\"\"\n",
    "    Create a fully populated z tensor\n",
    "    \"\"\"\n",
    "    z = Tensor(rank_ids=[\"M\", \"N\"])\n",
    "    z.setName(\"Z\")\n",
    "    z.setMutable(True)\n",
    "\n",
    "    z_m = z.getRoot()\n",
    "    #\n",
    "    # Hack to fill in all the entries in z\n",
    "    # This allows us to pretend the tensor is dense\n",
    "    #\n",
    "    n_fiber = Fiber(coords=range(N), initial=1)\n",
    "    m_fiber = Fiber(coords=range(M), initial=1)\n",
    "\n",
    "    for m, (z_n, _) in z_m << m_fiber:\n",
    "        for n, (z_ref, _) in z_n << n_fiber:\n",
    "            z_ref <<= 0\n",
    "            \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function for addressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAddress(tensor, x, y):\n",
    "    return (x*tensor.getShape()[1]+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are visualizing matrix multiplication we examined in Question 2. You will observe same cache statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_a = Cache(log_size=3, words_per_line=1)\n",
    "cache_b = Cache(log_size=3, words_per_line=1)\n",
    "cache_c = Cache(log_size=3, words_per_line=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Matrix Multiply\")\n",
    "\n",
    "z_MN = create_z()\n",
    "\n",
    "print(\"Output - before\")\n",
    "displayTensor(z_MN)\n",
    "\n",
    "z = z_MN.getRoot()\n",
    "a = a_MK.getRoot()\n",
    "b = b_KN.getRoot()\n",
    "\n",
    "canvas = createCanvas(a_MK, b_KN, z_MN)\n",
    "for m in range(M):\n",
    "    a_tile = [ (m, kt) for kt in range(K)]\n",
    "    for n in range(N):\n",
    "        logger(f\"Processing Z({m},{n}) = {z[m][n].payload}\")\n",
    "        b_tile = [ (kt, n) for kt in range(K)]\n",
    "        z_tile = (m, n)\n",
    "        for k in range(K):\n",
    "            logger(f\"Processing A({m},{k}) = {a[m][k].payload}\")\n",
    "            logger(f\"Processing B({k},{n}) = {b[k][n].payload}\")\n",
    "            \n",
    "            cache_a.load(getAddress(a, m, k))\n",
    "            cache_b.load(getAddress(b, k, n))\n",
    "              \n",
    "            cache_c.load(getAddress(z, m, n))\n",
    "            z[m][n] += a[m][k] * b[k][n]\n",
    "            addActivity(canvas, a_tile, b_tile, z_tile, worker=\"W\")\n",
    "            addFrame(canvas, (m,k), (k,n), (m,n))\n",
    "        \n",
    "            cache_c.store(getAddress(z, m, n))\n",
    "\n",
    "print(\"Output - after\")\n",
    "displayTensor(z)\n",
    "\n",
    "displayCanvas(canvas)\n",
    "\n",
    "if z_verify is None:\n",
    "    z_verify = deepcopy(z)\n",
    "\n",
    "# Print cache statistics\n",
    "print(\"-------Cache A--------\")\n",
    "cache_a.print_stats()\n",
    "print(\"-------Cache B--------\")\n",
    "cache_b.print_stats()\n",
    "print(\"-------Cache C--------\")\n",
    "cache_c.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiled Matrix Multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Here we are simulating __tiled__ matrix multiply. Caches are same as above. You do not need to code anything here. Why do cache statistics change (espeicllay for Cache B) when we use tiling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_your-answer-here_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_a = Cache(log_size=3, words_per_line=1)\n",
    "cache_b = Cache(log_size=3, words_per_line=1)\n",
    "cache_c = Cache(log_size=3, words_per_line=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Matrix Multiply\")\n",
    "\n",
    "z_MN = create_z()\n",
    "\n",
    "print(\"Output - before\")\n",
    "displayTensor(z_MN)\n",
    "\n",
    "z = z_MN.getRoot()\n",
    "a = a_MK.getRoot()\n",
    "b = b_KN.getRoot()\n",
    "\n",
    "canvas = createCanvas(a_MK, b_KN, z_MN)\n",
    "\n",
    "for k1 in range(K1):\n",
    "    for m1 in range(M1):\n",
    "        logger(f\"Processing Z({m},{n}) = {z[m][n].payload}\")\n",
    "        for n1 in range(N1):\n",
    "            a_tile = [ (m1*M0+mt, k1*K0+kt) for mt in range(M0)for kt in range(K0)]\n",
    "            b_tile = [ (k1*K0+kt, n1*N0+nt) for kt in range(K0)for nt in range(N0)]\n",
    "            z_tile = [ (m1*M0+mt, n1*N0+nt) for mt in range(M0)for nt in range(N0)]\n",
    "\n",
    "            for m0 in range(M0):\n",
    "                for n0 in range(N0):\n",
    "                    for k0 in range(K0):\n",
    "                        m = m1*M0+m0\n",
    "                        n = n1*N0+n0\n",
    "                        k = k1*K0+k0\n",
    "                        \n",
    "                        logger(f\"Processing A({m},{k}) = {a[m][k].payload}\")\n",
    "                        logger(f\"Processing B({k},{n}) = {b[k][n].payload}\")\n",
    "                        \n",
    "                        cache_a.load(getAddress(a, m, k))\n",
    "                        cache_b.load(getAddress(b, k, n))\n",
    "                        \n",
    "                        cache_c.load(getAddress(z, m, n))\n",
    "                        \n",
    "                        z[m][n] += a[m][k] * b[k][n]\n",
    "                        \n",
    "                        addActivity(canvas, a_tile, b_tile, z_tile, worker=\"W\")\n",
    "                        addFrame(canvas, (m,k), (k,n), (m,n))\n",
    "                        \n",
    "                        cache_c.store(getAddress(z, m, n))\n",
    "\n",
    "print(\"Output - after\")\n",
    "displayTensor(z)\n",
    "\n",
    "displayCanvas(canvas)\n",
    "\n",
    "if z_verify is None:\n",
    "    print(\"Result not verified\")\n",
    "else:\n",
    "    assert z == z_verify\n",
    "    \n",
    "# Print cache statistics\n",
    "print(\"-------Cache A--------\")\n",
    "cache_a.print_stats()\n",
    "print(\"-------Cache B--------\")\n",
    "cache_b.print_stats()\n",
    "print(\"-------Cache C--------\")\n",
    "cache_c.print_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
