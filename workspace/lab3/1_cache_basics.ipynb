{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solved-combat",
   "metadata": {},
   "source": [
    "## Name: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "owned-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from cache import Cache, CacheAssoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-strand",
   "metadata": {},
   "source": [
    "## Matrix Multiplication and Memory Access Pattern\n",
    "\n",
    "We will cheeck the memory access pattern for matrix multiplication. Consider this matrix multiplication:\n",
    "\n",
    "$$\n",
    "C_{m,n} = \\sum_k A_{m,k} \\times B_{k,n}\n",
    "$$\n",
    "\n",
    "Suppose our processor doesn't have a cache and directly loads operands from the main memory and stores the results back to the main memory. We want to count how many memory accesses are necessary to complete the computation, and estimate how much energy will be consumed for the memory access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "steady-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize values\n",
    "seed = 10\n",
    "random.seed(seed)\n",
    "\n",
    "M = 4\n",
    "K = 4\n",
    "N = 4\n",
    "\n",
    "# Matrix A (M x N)\n",
    "a_MK = []\n",
    "for m in range(M):\n",
    "    a_MK.append([random.randint(1, 9) for i in range(K)])\n",
    "\n",
    "\n",
    "# Matrix B (K x N)\n",
    "b_KN = []\n",
    "for k in range(K):\n",
    "    b_KN.append([random.randint(1, 9) for i in range(N)])\n",
    "    \n",
    "# print(a_MK)\n",
    "# print(b_KN)\n",
    "\n",
    "# ground truth for the result (M x N)\n",
    "c_MN = []\n",
    "for m in range(M):\n",
    "    temp = []\n",
    "    for n in range(N):\n",
    "        t = 0\n",
    "        for k in range(K):\n",
    "            t += a_MK[m][k] * b_KN[k][n]\n",
    "        temp.append(t)\n",
    "    c_MN.append(temp)\n",
    "# print(c_MN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-chorus",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "How many memory reads are in this loop nest? Break down the number of memory reads for each matrix (A, B, and C).\n",
    "\n",
    "How many memory writes are in this loop nest? Assume there is no register for storing partial sums, and reading and writing intermediate results should also be considered. Break down the number of memory writes for each matrix (A, B, and C).\n",
    "\n",
    "Fill in your answers in the table below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-taiwan",
   "metadata": {},
   "source": [
    "|   | A | B | C |\n",
    "| --- | --- | --- | --- |\n",
    "| Read | 64 | 64 | 64 |\n",
    "| Write | 0 | 0 | 64 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unavailable-morgan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Loop nest for the matrix multiplication\n",
    "c = np.zeros((M, N))\n",
    "for m in range(M):\n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            # load a\n",
    "            a = a_MK[m][k]\n",
    "            \n",
    "            # load b\n",
    "            b = b_KN[k][n]\n",
    "            \n",
    "            # compute partial sum\n",
    "            c[m][n] += a * b\n",
    "\n",
    "# Check the result\n",
    "print(np.all(c==np.asarray(c_MN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-entertainment",
   "metadata": {},
   "source": [
    "## Direct Mapped Cache\n",
    "\n",
    "Suppose our processor uses a directed mapped cache. We want to count the number of cache hit and miss for both read and write operations. Assume all data are initially stored in the main memory in __row major__ order. \n",
    "\n",
    "We are using two parameters when defining a cache: `log_size` and `words_per_line`. The total number of __words__ that a cache can store is $2^{log\\_size}$, and the number of words per line (block size) is `words_per_line`. For example, if a cache has `log_size=4`, and `words_per_line=2`, this cache can store total 16 words with block size of 2. We assume that our direct mapped cache uses write-through with no write allocation for store operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dressed-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_addr(addr, memory, cache):\n",
    "    val = memory[addr]\n",
    "    cache.load(addr)\n",
    "    return val\n",
    "    \n",
    "def write_addr(addr, memory, cache, val=0):\n",
    "    memory[addr] = val\n",
    "    cache.store(addr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-committee",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Modify the address that the processor has to request for read and write operation in the loop nest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "collect-necklace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "-------Cache A--------\n",
      "Cache Statistics:\n",
      "cache rd: 48\n",
      "cache wr: 0\n",
      "mem rd: 16\n",
      "mem wr: 0\n",
      "-------Cache B--------\n",
      "Cache Statistics:\n",
      "cache rd: 0\n",
      "cache wr: 0\n",
      "mem rd: 64\n",
      "mem wr: 0\n",
      "-------Cache C--------\n",
      "Cache Statistics:\n",
      "cache rd: 48\n",
      "cache wr: 64\n",
      "mem rd: 16\n",
      "mem wr: 64\n"
     ]
    }
   ],
   "source": [
    "# Define a main memory\n",
    "mem_log_size = 10\n",
    "memory = np.zeros(2**mem_log_size).astype(np.int32)\n",
    "memory[:M*K] = np.asarray(a_MK).flatten()\n",
    "memory[M*K:M*K+K*N] = np.asarray(b_KN).flatten()\n",
    "\n",
    "# Define a cache for each matrix (A, B, C)\n",
    "cache_a = Cache(log_size=3, words_per_line=1)\n",
    "cache_b = Cache(log_size=3, words_per_line=1)\n",
    "cache_c = Cache(log_size=3, words_per_line=1)\n",
    "\n",
    "# Loop nest for matrix multiplication\n",
    "for m in range(M):\n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "\n",
    "            # Your code: modify addr_a \n",
    "            addr_a = m*K + k + 0\n",
    "            a = read_addr(addr_a, memory, cache_a)\n",
    "            \n",
    "            # Your code: modify addr_b\n",
    "            addr_b = k*N + n + M*K\n",
    "            b = read_addr(addr_b, memory, cache_b)\n",
    "            \n",
    "            # Your code: modify addr_c\n",
    "            addr_c = m*N + n + M*K + K*N\n",
    "            psum = read_addr(addr_c, memory, cache_c)\n",
    "            \n",
    "            # compute partial sum\n",
    "            psum += a * b\n",
    "            write_addr(addr_c, memory, cache_c, int(psum))\n",
    "\n",
    "# Check the result\n",
    "print(np.all(memory[M*K+K*N:M*K+K*N+M*N].reshape((M, N))==np.asarray(c_MN)))\n",
    "\n",
    "# Print cache statistics\n",
    "print(\"-------Cache A--------\")\n",
    "cache_a.print_stats()\n",
    "print(\"-------Cache B--------\")\n",
    "cache_b.print_stats()\n",
    "print(\"-------Cache C--------\")\n",
    "cache_c.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-michigan",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Now, run the same loop nest using caches with the same size, but with different words per line (block size). Explain why the statistics for Cache A is different from the previous case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-terrace",
   "metadata": {},
   "source": [
    "The cache with >1 word per line can exploit **data locality** to reduce cache misses, because our multiplication algorithm performs concordant traversal of the input matrices (in terms which apply to dense matrices, this means that we are iterating through elements of the row-major matrix representation in consecutive order.) A consequence of concordant traversal is that if we have just accessed A[i]  (i and j here are flattened positions), then it is very likely that we will subsequently access A[i+1]. So when the first element A[i] of a row is read, for example, the cache line will hold not just A[i] but also {A[i+d] for d <= cache line words}. Then when the concordant traversal accesses the next element A[i+1] in the row, it is a cache hit. Effectively, long cache lines increase cache hits by anticipating that programs will implement local, consecutive memory accesses.\n",
    "\n",
    "However, B cannot reap the benefits of the long cache lines, because we are not performing a concordant traversal of B - the inner-most loop of the multiplication algorithm jumps from row to row of B, and is therefore effectively making strided jumps through the flattened row-major represention of B. Therefore, the assumption built into the long cache-line optimization - that data access is local and consecutive - is incorrect for B, and so there are no cache hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "yellow-israeli",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "-------Cache A--------\n",
      "Cache Statistics:\n",
      "cache rd: 56\n",
      "cache wr: 0\n",
      "mem rd: 8\n",
      "mem wr: 0\n",
      "-------Cache B--------\n",
      "Cache Statistics:\n",
      "cache rd: 0\n",
      "cache wr: 0\n",
      "mem rd: 64\n",
      "mem wr: 0\n",
      "-------Cache C--------\n",
      "Cache Statistics:\n",
      "cache rd: 56\n",
      "cache wr: 64\n",
      "mem rd: 8\n",
      "mem wr: 64\n"
     ]
    }
   ],
   "source": [
    "# Define a main memory\n",
    "mem_log_size = 10\n",
    "memory = np.zeros(2**mem_log_size).astype(np.int32)\n",
    "memory[:M*K] = np.asarray(a_MK).flatten()\n",
    "memory[M*K:M*K+K*N] = np.asarray(b_KN).flatten()\n",
    "\n",
    "# Define a cache for each matrix (A, B, C)\n",
    "cache_a = Cache(log_size=3, words_per_line=2)\n",
    "cache_b = Cache(log_size=3, words_per_line=2)\n",
    "cache_c = Cache(log_size=3, words_per_line=2)\n",
    "\n",
    "# Loop nest for matrix multiplication\n",
    "for m in range(M):\n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "\n",
    "            # Your code: modify addr_a \n",
    "            addr_a = m*K + k + 0\n",
    "            a = read_addr(addr_a, memory, cache_a)\n",
    "            \n",
    "            # Your code: modify addr_b\n",
    "            addr_b = k*N + n + M*K\n",
    "            b = read_addr(addr_b, memory, cache_b)\n",
    "            \n",
    "            # Your code: modify addr_c\n",
    "            addr_c = m*N + n + M*K + K*N\n",
    "            psum = read_addr(addr_c, memory, cache_c)\n",
    "            \n",
    "            # compute partial sum\n",
    "            psum += a * b\n",
    "            write_addr(addr_c, memory, cache_c, int(psum))\n",
    "\n",
    "# Check the result\n",
    "print(np.all(memory[M*K+K*N:M*K+K*N+M*N].reshape((M, N))==np.asarray(c_MN)))\n",
    "\n",
    "# Print cache statistics\n",
    "print(\"-------Cache A--------\")\n",
    "cache_a.print_stats()\n",
    "print(\"-------Cache B--------\")\n",
    "cache_b.print_stats()\n",
    "print(\"-------Cache C--------\")\n",
    "cache_c.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-champagne",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Suppose we store data of Matrix B to the main memory in __column major__ order. Change the address that are requested by the processor, and explain the difference of the statistics for Cache B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-wednesday",
   "metadata": {},
   "source": [
    "\n",
    "The cache statistics demonstrate that 50% of B reads are now cache hits. Our multiplication algorithm naturally iterates through B in column-major order (the inner loop iterates over rank k which corresponds to columns of B); by adopting a column-major representation, the iteration because concordant and so there is significant data locality. If B[i] is accessed, it is very likely B[i+1] will be accessed next, and so the long cache lines can hold chunks of words from a column of B in anticipation of local consecutive accesses. This increases the number of cache hits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "speaking-career",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "-------Cache A--------\n",
      "Cache Statistics:\n",
      "cache rd: 56\n",
      "cache wr: 0\n",
      "mem rd: 8\n",
      "mem wr: 0\n",
      "-------Cache B--------\n",
      "Cache Statistics:\n",
      "cache rd: 32\n",
      "cache wr: 0\n",
      "mem rd: 32\n",
      "mem wr: 0\n",
      "-------Cache C--------\n",
      "Cache Statistics:\n",
      "cache rd: 56\n",
      "cache wr: 64\n",
      "mem rd: 8\n",
      "mem wr: 64\n"
     ]
    }
   ],
   "source": [
    "mem_log_size = 10\n",
    "memory_col = np.zeros(2**mem_log_size).astype(np.int32)\n",
    "memory_col[:M*K] = np.asarray(a_MK).flatten()\n",
    "memory_col[M*K:M*K+K*N] = np.asarray(b_KN).transpose().flatten()\n",
    "\n",
    "# Define a cache for each matrix (A, B, C)\n",
    "cache_a = Cache(log_size=3, words_per_line=2)\n",
    "cache_b = Cache(log_size=3, words_per_line=2)\n",
    "cache_c = Cache(log_size=3, words_per_line=2)\n",
    "\n",
    "# Loop nest for matrix multiplication\n",
    "for m in range(M):\n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "\n",
    "            # Your code: modify addr_a \n",
    "            addr_a = m*K + k + 0\n",
    "            a = read_addr(addr_a, memory_col, cache_a)\n",
    "            \n",
    "            # Your code: modify addr_b\n",
    "            addr_b = n*K + M*K + k \n",
    "            b = read_addr(addr_b, memory_col, cache_b)\n",
    "            \n",
    "            # Your code: modify addr_c\n",
    "            addr_c = m*N + n + M*K + K*N\n",
    "            psum = read_addr(addr_c, memory_col, cache_c)\n",
    "            \n",
    "            # compute partial sum\n",
    "            psum += a * b\n",
    "            write_addr(addr_c, memory_col, cache_c, int(psum))\n",
    "\n",
    "# Check the result\n",
    "print(np.all(memory_col[M*K+K*N:M*K+K*N+M*N].reshape((M, N))==np.asarray(c_MN)))\n",
    "\n",
    "# Print cache statistics\n",
    "print(\"-------Cache A--------\")\n",
    "cache_a.print_stats()\n",
    "print(\"-------Cache B--------\")\n",
    "cache_b.print_stats()\n",
    "print(\"-------Cache C--------\")\n",
    "cache_c.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-commodity",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Suppose our loop nest order is different, from M -> N -> K to K -> N -> M. Assume all conditions are identical to Question 2. Explain cache statistics compared to those in Question 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-australia",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "modified-workshop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "-------Cache A--------\n",
      "Cache Statistics:\n",
      "cache rd: 0\n",
      "cache wr: 0\n",
      "mem rd: 64\n",
      "mem wr: 0\n",
      "-------Cache B--------\n",
      "Cache Statistics:\n",
      "cache rd: 48\n",
      "cache wr: 0\n",
      "mem rd: 16\n",
      "mem wr: 0\n",
      "-------Cache C--------\n",
      "Cache Statistics:\n",
      "cache rd: 0\n",
      "cache wr: 64\n",
      "mem rd: 64\n",
      "mem wr: 64\n"
     ]
    }
   ],
   "source": [
    "mem_log_size = 10\n",
    "memory = np.zeros(2**mem_log_size).astype(np.int32)\n",
    "memory[:M*K] = np.asarray(a_MK).flatten()\n",
    "memory[M*K:M*K+K*N] = np.asarray(b_KN).flatten()\n",
    "\n",
    "# Define a cache for each matrix (A, B, C)\n",
    "cache_a = Cache(log_size=3, words_per_line=1)\n",
    "cache_b = Cache(log_size=3, words_per_line=1)\n",
    "cache_c = Cache(log_size=3, words_per_line=1)\n",
    "\n",
    "for k in range(K):\n",
    "    for n in range(N):\n",
    "        for m in range(M):\n",
    "            # Your code: modify addr_a \n",
    "            addr_a = m*K + k + 0\n",
    "            a = read_addr(addr_a, memory, cache_a)\n",
    "            \n",
    "            # Your code: modify addr_a \n",
    "            addr_b = k*N + n + M*K\n",
    "            b = read_addr(addr_b, memory, cache_b)\n",
    "            \n",
    "            # Your code: modify addr_a \n",
    "            addr_c = m*N + n + M*K + K*N\n",
    "            psum = read_addr(addr_c, memory, cache_c)\n",
    "\n",
    "            # compute partial sum\n",
    "            psum += a * b\n",
    "            write_addr(addr_c, memory, cache_c, int(psum))\n",
    "\n",
    "\n",
    "# Check the result\n",
    "print(np.all(memory[M*K+K*N:M*K+K*N+M*N].reshape((M, N))==np.asarray(c_MN)))\n",
    "\n",
    "# Print cache statistics\n",
    "print(\"-------Cache A--------\")\n",
    "cache_a.print_stats()\n",
    "print(\"-------Cache B--------\")\n",
    "cache_b.print_stats()\n",
    "print(\"-------Cache C--------\")\n",
    "cache_c.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-question",
   "metadata": {},
   "source": [
    "## Set Associative Cache\n",
    "\n",
    "Now, we will consider a set associative cache. This cache has another parameter, `num_ways`, that specifies the number of ways. For example, if `log_size=4`, `words_per_line=2`, and `num_ways=2`, this cache can store total 16 words and there are total 4 sets, where each set has two ways and the block size will be two. Similar to the direct mapped cache we discussed above, our set associative cache uses write-through with no write allocation for store, and uses Bit Psuedo Least Recently Used to replace cache entries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-marine",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Let's run the same loop nest as in Question 2, except for that we use one large cache instead of using three different caches for each matrix. Note that we are still using a direct mapped cache here. Explain the difference in the total cache hit and miss ratio, compared to Question 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-marsh",
   "metadata": {},
   "source": [
    "\n",
    "_your-answer-here_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hundred-rings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "-------Cache--------\n",
      "Cache Statistics:\n",
      "cache rd: 191\n",
      "cache wr: 64\n",
      "mem rd: 1\n",
      "mem wr: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_230/1569185727.py:28: RuntimeWarning: overflow encountered in int_scalars\n",
      "  psum += a * b\n"
     ]
    }
   ],
   "source": [
    "# Define a main memory\n",
    "mem_log_size = 10\n",
    "memory = np.zeros(2**mem_log_size).astype(np.int32)\n",
    "memory[:M*K] = np.asarray(a_MK).flatten()\n",
    "memory[M*K:M*K+K*N] = np.asarray(b_KN).flatten()\n",
    "\n",
    "# Define a cache for each matrix (A, B, C)\n",
    "cache = Cache(log_size=5, words_per_line=2)\n",
    "\n",
    "# Loop nest for matrix multiplication\n",
    "for m in range(M):\n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "\n",
    "            # Your code: modify addr_a \n",
    "            addr_a = 0\n",
    "            a = read_addr(addr_a, memory, cache)\n",
    "            \n",
    "            # Your code: modify addr_b\n",
    "            addr_b = 0\n",
    "            b = read_addr(addr_b, memory, cache)\n",
    "            \n",
    "            # Your code: modify addr_c\n",
    "            addr_c = 0\n",
    "            psum = read_addr(addr_c, memory, cache)\n",
    "            \n",
    "            # compute partial sum\n",
    "            psum += a * b\n",
    "            write_addr(addr_c, memory, cache, int(psum))\n",
    "            \n",
    "            # debug\n",
    "            # print(\"---------------------\")\n",
    "            # print(addr_a, addr_b, addr_c)\n",
    "\n",
    "# Check the result\n",
    "print(np.all(memory[M*K+K*N:M*K+K*N+M*N].reshape((M, N))==np.asarray(c_MN)))\n",
    "\n",
    "# Print cache statistics\n",
    "print(\"-------Cache--------\")\n",
    "cache.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-flood",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Observe the cache access pattern when we use a set associative cache with 2 ways. Explain the difference compared to Question 6. Generally, in which cases using set associative caches beneficial compared to direct mapped caches? If we use three separate caches for each matrix as before, do set associative caches provide benefits?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-dietary",
   "metadata": {},
   "source": [
    "\n",
    "_your-answer-here_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acceptable-terrorist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "-------Cache--------\n",
      "Cache Statistics:\n",
      "cache rd: 191\n",
      "cache wr: 64\n",
      "mem rd: 1\n",
      "mem wr: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_230/4283516884.py:28: RuntimeWarning: overflow encountered in int_scalars\n",
      "  psum += a * b\n"
     ]
    }
   ],
   "source": [
    "# Define a main memory\n",
    "mem_log_size = 10\n",
    "memory = np.zeros(2**mem_log_size).astype(np.int32)\n",
    "memory[:M*K] = np.asarray(a_MK).flatten()\n",
    "memory[M*K:M*K+K*N] = np.asarray(b_KN).flatten()\n",
    "\n",
    "# Define a cache for each matrix (A, B, C)\n",
    "cache = CacheAssoc(log_size=5, words_per_line=2, num_ways=2)\n",
    "\n",
    "# Loop nest for matrix multiplication\n",
    "for m in range(M):\n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "\n",
    "            # Your code: modify addr_a \n",
    "            addr_a = 0\n",
    "            a = read_addr(addr_a, memory, cache)\n",
    "            \n",
    "            # Your code: modify addr_b\n",
    "            addr_b = 0\n",
    "            b = read_addr(addr_b, memory, cache)\n",
    "            \n",
    "            # Your code: modify addr_c\n",
    "            addr_c = 0\n",
    "            psum = read_addr(addr_c, memory, cache)\n",
    "            \n",
    "            # compute partial sum\n",
    "            psum += a * b\n",
    "            write_addr(addr_c, memory, cache, int(psum))\n",
    "            \n",
    "            # debug\n",
    "            # print(\"---------------------\")\n",
    "            # print(addr_a, addr_b, addr_c)\n",
    "\n",
    "# Check the result\n",
    "print(np.all(memory[M*K+K*N:M*K+K*N+M*N].reshape((M, N))==np.asarray(c_MN)))\n",
    "\n",
    "# Print cache statistics\n",
    "print(\"-------Cache--------\")\n",
    "cache.print_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
